{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8deb4ace-27c1-4f49-87c3-99f2457161d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch,torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import random,numpy.random\n",
    "import os\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af5e6b5-467d-4eed-a5b6-6e5efdcbe19b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n1 = nn.Sequential(nn.ConvTranspose2d(110,512,4,1,0,bias=False), \n",
    "                                 nn.BatchNorm2d(512), \n",
    "                                 nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n2=nn.Sequential(nn.ConvTranspose2d(512,256,4,2,1,bias=False), \n",
    "                                 nn.BatchNorm2d(256), \n",
    "                                 nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n3=nn.Sequential(nn.ConvTranspose2d(256,256,4,2,1,bias=False), \n",
    "                                 nn.BatchNorm2d(256), \n",
    "                                 nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n4=nn.Sequential(nn.ConvTranspose2d(256,128,4,2,1,bias=False), \n",
    "                                 nn.BatchNorm2d(128), \n",
    "                                 nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n5=nn.Sequential(nn.ConvTranspose2d(128,128,4,2,1,bias=False), \n",
    "                                 nn.BatchNorm2d(128), \n",
    "                                 nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n6=nn.ConvTranspose2d(128,3,4,2,1,bias=False)\n",
    "        self.n7=nn.Tanh()\n",
    "    def forward(self, noise,label):\n",
    "        x = torch.cat((noise, label),dim=1)  #将标签与数据拼接 (N,channels,128,128),(N,n_classes, 128,128)->(N,channels+nc_classes,128,128)\n",
    "        x=self.n1(x)\n",
    "        x=self.n2(x)\n",
    "        x=self.n3(x)\n",
    "        x=self.n4(x)\n",
    "        x=self.n5(x)\n",
    "        x=self.n6(x)\n",
    "        x=self.n7(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3a902b-fb8b-4e26-85fd-2daf240ef202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 鉴别器结构\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n1=nn.Sequential(nn.Conv2d(13,128, 4,2,1, bias=False), \n",
    "                              nn.BatchNorm2d(128),\n",
    "                              nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n2=nn.Sequential(nn.Conv2d(128,128, 4,2,1, bias=False), \n",
    "                              nn.BatchNorm2d(128),\n",
    "                              nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n3=nn.Sequential(nn.Conv2d(128,256, 4,2,1, bias=False), \n",
    "                              nn.BatchNorm2d(256),\n",
    "                              nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n4=nn.Sequential(nn.Conv2d(256,256, 4,2,1, bias=False), \n",
    "                              nn.BatchNorm2d(256),\n",
    "                              nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n5=nn.Sequential(nn.Conv2d(256,512, 4,2,1, bias=False), \n",
    "                              nn.BatchNorm2d(512),\n",
    "                              nn.LeakyReLU(0.2,inplace=True))\n",
    "        self.n6=nn.Sequential(nn.Conv2d(512,1, 4,1,0, bias=False))\n",
    "        self.n7=nn.Flatten()     #(N,1)\n",
    "        self.n8=nn.Sigmoid()\n",
    "  \n",
    "    def forward(self, img, label):\n",
    "        x = torch.cat((img, label),dim=1)\n",
    "        x=self.n1(x)\n",
    "        x=self.n2(x)\n",
    "        x=self.n3(x)\n",
    "        x=self.n4(x)\n",
    "        x=self.n5(x)\n",
    "        x=self.n6(x)\n",
    "        x=self.n7(x)\n",
    "        x=self.n8(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e41a8f4-bc1c-4a67-96a8-4400454f25b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#加载数据集\n",
    "my_transform = transforms.Compose([\n",
    "        transforms.Resize((128,128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "254cf383-b99e-4031-b756-31e10afca358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./Data', train=False, download=True,transform=my_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b1a91e-45b2-40ed-9c7a-8008b8409a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a1c5ad0-0ed9-45e6-93f8-0e382e9734c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#将标签进行one-hot编码\n",
    "def to_categrical(y: torch.FloatTensor):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(list(range(0,10)))\n",
    "    y_one_hot = lb.transform(y.cpu())\n",
    "    floatTensor = torch.FloatTensor(y_one_hot)\n",
    "    return floatTensor\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e693fb-e9f4-49dd-8693-b6f41a252496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainer(batch, netD, netG, optimizerD, optimizerG, loss_func, device):\n",
    "    # 将模型参数设为训练模式\n",
    "    netD.train()  # 训练中需要求模型参数的梯度，所有参数都处于可训练模式\n",
    "    netG.train()\n",
    "    # 从batch中获取输入数据和标签(不一定有标签)\n",
    "    x, y = batch\n",
    "    # 将数据存入对应设备中\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    target = to_categrical(y).unsqueeze(2).unsqueeze(3).float()  #加到噪声上 torch.Size([N, n_classes, 1, 1])\n",
    "    target = target.to(device)\n",
    "    label = target.repeat(1, 1, x.size(2), x.size(3))   #加到数据上(N,n_classes,128,128)\n",
    "    label = label.to(device)\n",
    "    label_r = torch.full((x.size(0),1), 1.0) # 按照shape，创建一模一样的向量\n",
    "    label_r=label_r.to(device)\n",
    " \n",
    "    #（1）训练判别器 \n",
    "    #training real data\n",
    "    netD.zero_grad()\n",
    "    output1 = netD(x,label) #将标签与数据拼接 (N,channels,128,128),(N,n_classes, 128,128)->(N,channels+nc_classes,128,128)\n",
    "    \n",
    "    loss_D1 = loss_func(output1, label_r)\n",
    "    \n",
    "        \n",
    "    #training fake data,拼接噪声和标签\n",
    "    noise_z = torch.randn(x.size(0), 100, 1, 1) # (N,噪声向量维度100,1,1)\n",
    "    noise_z = noise_z.to(device)\n",
    "    \n",
    "    fake_data = netG(noise_z,target) # 假数据来自噪声\n",
    "\n",
    "    label_f = torch.full((x.size(0),1), 0.0) # (N,1)\n",
    "    label_f = label_f.to(device)\n",
    "    \n",
    "    output2 = netD(fake_data.detach(),label) # (N,1)\n",
    "    loss_D2 = loss_func(output2, label_f)\n",
    "    \n",
    "    loss_D=loss_D1+loss_D2\n",
    "    loss_D.backward()\n",
    "    \n",
    "    #更新判别器\n",
    "    optimizerD.step()\n",
    "        \n",
    "    #（2）训练生成器，首先清空梯度\n",
    "    netG.zero_grad()\n",
    "    output2 = netD(fake_data,label)   \n",
    "    loss_G = loss_func(output2, label_r)  # 像真实图像靠近\n",
    "    loss_G.backward()\n",
    "        \n",
    "    #更新生成器\n",
    "    optimizerG.step()\n",
    "        \n",
    "    # 计算准确率\n",
    "    correct_predictions1 = (output1>0.5).sum().item()  # 统计在正确数据中预测正确的数量\n",
    "    correct_predictions2 = (output2<0.5).sum().item()  # 统计在假数据中预测正确的数量\n",
    "    correct_predictions=correct_predictions1+correct_predictions2\n",
    "    return loss_D.item() / y.shape[0], loss_G.item()/y.shape[0], correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b10aa3e9-36b4-4c24-ae92-2d0ae38120ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_fakeimg(netG,target_label):\n",
    "    sample_dir = \"fakeimg2\"\n",
    "    # 创建生成图像的目录\n",
    "    if not os.path.exists(sample_dir):\n",
    "        os.makedirs(sample_dir)\n",
    "    noise_z1 = torch.randn(64, 100, 1, 1).cuda()\n",
    "    label = to_categrical(torch.full((64,1), target_label)).unsqueeze(2).unsqueeze(3).float() #将标签编码\n",
    "    label=label.cuda()\n",
    "    fake_data = netG(noise_z1,label)            \n",
    "    #保存图片\n",
    "    data = fake_data.detach().permute(0,2,3,1) # 通道数放最后\n",
    "    data = data.cpu()\n",
    "    data = np.array(data)\n",
    "    #保存单张图片，将数据还原\n",
    "    data = (data*0.5+0.5) # 缩放，否则某些像素点可能会小于0\n",
    "    plt.imsave('./fakeimg2.png', data[0])\n",
    "    torchvision.utils.save_image(fake_data[:64]*0.5+0.5,'./fakeimg2/class_%d.png'%target_label,nrow=8,normalize=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c82a73d-ede5-43ab-a05f-7ee7c0a28e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(netG,netD):\n",
    "    sample_dir = \"model_cGAN\"\n",
    "    # 创建生成图像的目录\n",
    "    if not os.path.exists(sample_dir):\n",
    "        os.makedirs(sample_dir)\n",
    "    state = {'net_G': netG.state_dict(),'net_D': netD.state_dict()}\n",
    "    torch.save(state, './model_cGAN/net.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "882e7311-8083-4abc-8ab6-9b01b53ba07a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.0210 | 0.0212 ｜Accuracy: 73.19%\n",
      "Epoch: 1 Training Loss: 0.0211 | 0.0181 ｜Accuracy: 68.29%\n",
      "Epoch: 2 Training Loss: 0.0210 | 0.0184 ｜Accuracy: 70.62%\n",
      "Epoch: 3 Training Loss: 0.0210 | 0.0190 ｜Accuracy: 69.88%\n",
      "Epoch: 4 Training Loss: 0.0209 | 0.0197 ｜Accuracy: 70.53%\n",
      "Epoch: 5 Training Loss: 0.0205 | 0.0206 ｜Accuracy: 72.95%\n",
      "Epoch: 6 Training Loss: 0.0203 | 0.0229 ｜Accuracy: 73.39%\n",
      "Epoch: 7 Training Loss: 0.0199 | 0.0235 ｜Accuracy: 74.70%\n",
      "Epoch: 8 Training Loss: 0.0194 | 0.0251 ｜Accuracy: 76.85%\n",
      "Epoch: 9 Training Loss: 0.0197 | 0.0237 ｜Accuracy: 74.14%\n",
      "Epoch: 10 Training Loss: 0.0194 | 0.0238 ｜Accuracy: 73.67%\n",
      "Epoch: 11 Training Loss: 0.0196 | 0.0239 ｜Accuracy: 75.37%\n",
      "Epoch: 12 Training Loss: 0.0195 | 0.0244 ｜Accuracy: 76.00%\n",
      "Epoch: 13 Training Loss: 0.0189 | 0.0251 ｜Accuracy: 76.55%\n",
      "Epoch: 14 Training Loss: 0.0157 | 0.0349 ｜Accuracy: 84.02%\n",
      "Epoch: 15 Training Loss: 0.0041 | 0.0766 ｜Accuracy: 96.71%\n",
      "Epoch: 16 Training Loss: 0.0089 | 0.0801 ｜Accuracy: 92.11%\n",
      "Epoch: 17 Training Loss: 0.0147 | 0.0435 ｜Accuracy: 84.94%\n",
      "Epoch: 18 Training Loss: 0.0144 | 0.0428 ｜Accuracy: 84.73%\n",
      "Epoch: 19 Training Loss: 0.0124 | 0.0463 ｜Accuracy: 87.55%\n",
      "Epoch: 20 Training Loss: 0.0003 | 0.0962 ｜Accuracy: 100.00%\n",
      "Epoch: 21 Training Loss: 0.0030 | 0.1235 ｜Accuracy: 98.61%\n",
      "Epoch: 22 Training Loss: 0.0107 | 0.0608 ｜Accuracy: 90.67%\n",
      "Epoch: 23 Training Loss: 0.0119 | 0.0551 ｜Accuracy: 87.86%\n",
      "Epoch: 24 Training Loss: 0.0151 | 0.0445 ｜Accuracy: 82.59%\n",
      "Epoch: 25 Training Loss: 0.0127 | 0.0438 ｜Accuracy: 88.03%\n",
      "Epoch: 26 Training Loss: 0.0033 | 0.0753 ｜Accuracy: 97.46%\n",
      "Epoch: 27 Training Loss: 0.0001 | 0.1080 ｜Accuracy: 100.00%\n",
      "Epoch: 28 Training Loss: 0.0013 | 0.1490 ｜Accuracy: 99.51%\n",
      "Epoch: 29 Training Loss: 0.0064 | 0.0939 ｜Accuracy: 95.94%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    netG = Generator().cuda()\n",
    "    netD = Discriminator().cuda()\n",
    "    loss_func = torch.nn.BCELoss()\n",
    "    device = \"cuda\"\n",
    "    # setup optimizer\n",
    "    # optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0002,betas=(0.5, 0.999))\n",
    "    optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0002,betas=(0.5,0.999))\n",
    "    optimizerD = torch.optim.RMSprop(netD.parameters(),\n",
    "                    lr=0.0002,\n",
    "                    alpha=0.99,\n",
    "                    eps=1e-08,\n",
    "                    weight_decay=0,\n",
    "                    momentum=0,)\n",
    "    total_ep = 30\n",
    "    for ep in range(total_ep):\n",
    "        total_lossG = 0.0\n",
    "        total_lossD = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for batch in train_loader:\n",
    "            loss_D, loss_G, correct_predictions = trainer(batch, netD, netG, optimizerD, optimizerG, loss_func, device)\n",
    "            total_lossD += loss_D\n",
    "            total_lossG += loss_G\n",
    "            total_correct += correct_predictions\n",
    "            total_samples += batch[1].shape[0]\n",
    "            # print(total_lossD,total_lossG)\n",
    "        average_lossD = total_lossD / len(train_loader)\n",
    "        average_lossG = total_lossG / len(train_loader)\n",
    "        accuracy = total_correct / (2*total_samples)\n",
    "        print(f\"Epoch: {ep} Training Loss: {average_lossD:.4f} | {average_lossG:.4f} ｜Accuracy: {accuracy * 100:.2f}%\")\n",
    "    generate_fakeimg(netG,5)   # 生成class5的图片\n",
    "    save_model(netG,netD)      # 保存模型参数\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2638855c-a3ed-49bb-a2f5-2bcba972236a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
